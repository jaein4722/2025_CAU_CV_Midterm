{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd08f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from train_utils import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53145ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ex_dict(ex_dict, config: BaseConfig, initial = False):\n",
    "    if initial:\n",
    "        ex_dict['Experiment Time'] = config.experiment_time\n",
    "    ex_dict['Epochs'] = config.epochs\n",
    "    ex_dict['Batch Size'] = config.batch\n",
    "    ex_dict['Device'] = config.device\n",
    "    ex_dict['Optimizer'] = config.optimizer\n",
    "    ex_dict['LR'] = config.lr0\n",
    "    ex_dict['Weight Decay'] = config.weight_decay\n",
    "    ex_dict['Momentum'] = config.momentum\n",
    "    ex_dict['Image Size'] = config.imgsz\n",
    "    ex_dict['Output Dir'] = config.output_dir\n",
    "    ex_dict['LRF'] = config.lrf      # Fimal Cosine decay learning rate\n",
    "    ex_dict['Cos LR'] = config.cos_lr    # Apply Cosine Scheduler\n",
    "\n",
    "    # Data Augmentation\n",
    "    ex_dict['hsv_h'] = config.hsv_h\n",
    "    ex_dict['hsv_s'] = config.hsv_s\n",
    "    ex_dict['hsv_v'] = config.hsv_v\n",
    "    ex_dict['degrees'] = config.degrees\n",
    "\n",
    "    ex_dict['translate'] = config.translate\n",
    "    ex_dict['scale'] = config.scale\n",
    "    ex_dict['flipud'] = config.flipud\n",
    "    ex_dict['fliplr'] = config.fliplr\n",
    "    ex_dict['mosaic'] = config.mosaic\n",
    "    ex_dict['mixup'] = config.mixup\n",
    "    ex_dict['copy_paste'] = config.copy_paste\n",
    "    \n",
    "    ex_dict['box'] = config.box\n",
    "    ex_dict['cls'] = config.cls\n",
    "    ex_dict['dfl'] = config.dfl\n",
    "    \n",
    "    return ex_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad4f17-85f9-4424-8290-61973707b21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_config = BaseConfig()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "configs = [v8Config(), v9Config(), v10Config(), v11Config(), v12Config()]\n",
    "print('Experiment Start Time:', base_config.experiment_time)\n",
    "ex_dict = {}\n",
    "update_ex_dict(ex_dict, base_config, initial=True)\n",
    "\n",
    "# loss weight\n",
    "loss_config = {\n",
    "    'yolov5n': {'box': 5.0, 'cls': 0.7, 'dfl': 1.0}, # dfl is not used in YOLOv5 models; ignored during training\n",
    "    'yolov8n': {'box': 7.5, 'cls': 0.5, 'dfl': 1.5},\n",
    "    'yolo11n': {'box': 7.5, 'cls': 0.5, 'dfl': 1.5}\n",
    "}\n",
    "\n",
    "for iteration in range(base_config.iterations[0], base_config.iterations[1]+1):\n",
    "    print(f'(Iter {iteration})')\n",
    "    seed = iteration\n",
    "    ex_dict['Iteration'] = iteration\n",
    "    \n",
    "    for j, Dataset_Name in enumerate(base_config.dataset_names):\n",
    "        print(f'Dataset: {Dataset_Name} ({j+1}/{len(base_config.dataset_names)})'); \n",
    "        control_random_seed(seed)\n",
    "        \n",
    "        data_yaml_path = f\"{base_config.dataset_root}/{Dataset_Name}/data_iter_{iteration:02d}.yaml\"\n",
    "        with open(data_yaml_path, 'r') as f:\n",
    "            data_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "            \n",
    "        ex_dict['Dataset Name'] = Dataset_Name\n",
    "        ex_dict['Data Config'] = data_yaml_path\n",
    "        ex_dict['Number of Classes'] = data_config['nc']\n",
    "        ex_dict['Class Names'] = data_config['names']\n",
    "        update_dataset_paths(base_config.dataset_root, Dataset_Name, iteration)\n",
    "        \n",
    "        for k, config in enumerate(configs):\n",
    "            update_ex_dict(ex_dict, config)\n",
    "            print(f'{config.model_name} ({k+1}/{len(config.model_name)}) (Iter {iteration})', end=' ')\n",
    "            print(f'Dataset: {Dataset_Name} ({j+1}/{len(base_config.dataset_names)})', end=' ')\n",
    "            control_random_seed(seed)\n",
    "            \n",
    "            # Load base model config\n",
    "            temp_model = YOLO(f'{config.model_name}.yaml', verbose=False)\n",
    "            original_model_dict = temp_model.model.yaml\n",
    "\n",
    "            # Save original yaml\n",
    "            os.makedirs(\"models\", exist_ok=True)\n",
    "            original_yaml_path = os.path.join(\"models\", f\"{config.model_name}_original.yaml\")\n",
    "            with open(original_yaml_path, 'w') as f:\n",
    "                yaml.dump(original_model_dict, f, sort_keys=False)\n",
    "\n",
    "            # Customize depth/width and modify corresponding scale value\n",
    "            custom_model_dict = original_model_dict.copy()\n",
    "            scale_key = config.model_name.strip()[-1]\n",
    "            custom_depth = 0.2\n",
    "            custom_width = 0.25\n",
    "\n",
    "            # Update scale-specific values\n",
    "            if 'scales' in custom_model_dict and scale_key in custom_model_dict['scales']:\n",
    "                custom_model_dict['scales'][scale_key][0] = custom_depth\n",
    "                custom_model_dict['scales'][scale_key][1] = custom_width\n",
    "\n",
    "            # Also explicitly add depth_multiple and width_multiple\n",
    "            custom_model_dict['depth_multiple'] = custom_depth\n",
    "            custom_model_dict['width_multiple'] = custom_width\n",
    "\n",
    "            # Save customized yaml\n",
    "            custom_yaml_path = os.path.join(\"models\", f\"{config.model_name}_custom.yaml\")\n",
    "            with open(custom_yaml_path, 'w') as f:\n",
    "                yaml.dump(custom_model_dict, f, sort_keys=False)\n",
    "\n",
    "            # Load modified model\n",
    "            model = YOLO(custom_yaml_path, verbose=False)\n",
    "            ex_dict['Model Name'] = config.model_name\n",
    "            ex_dict['Model']=model\n",
    "            update_ex_dict(ex_dict, config)\n",
    "            \n",
    "            start = timeit.default_timer()\n",
    "            \n",
    "            ex_dict = train_model(ex_dict, config)\n",
    "            ex_dict = evaluate_model(ex_dict)\n",
    "            \n",
    "            ex_dict['Train-Test Time'] = timeit.default_timer() - start\n",
    "            \n",
    "            eval_dict = format_measures(ex_dict.get('Test Results'))\n",
    "            output_csv = f\"{ex_dict['Experiment Time']}_Results.csv\"\n",
    "            merge_and_update_df(ex_dict, eval_dict, output_csv, exclude_columns=['Model', 'Train Results', 'Test Results'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badeda7a-b5bf-4fbf-a241-0fb3f006857f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
